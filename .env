# Milvus Configuration
MILVUS_URI="grpc://localhost:19530" # Or your Milvus Cloud URI
MILVUS_TOKEN="your-milvus-api-key" # Optional: If using token authentication for Milvus Cloud
MILVUS_COLLECTION_NAME="rag_documents"

# Embedding Model Configuration
EMBEDDING_PROVIDER="openai" # 可选值: openai, huggingface, qwen, ollama, jina, custom
# OpenAI Embeddings
OPENAI_API_KEY="your-openai-api-key"
EMBEDDING_MODEL_NAME="text-embedding-ada-002"

# HuggingFace Embeddings
HUGGINGFACE_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"

# Qwen Embeddings (via Dashscope)
# Using DASHSCOPE_API_KEY (shared with LLM section)
QWEN_EMBEDDING_MODEL_NAME="text-embedding-v2"

# Ollama (local model)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_EMBEDDING_MODEL="llama2"

# Jina AI Embeddings
JINA_API_KEY="your-jina-api-key"
JINA_EMBEDDING_MODEL="jina-embeddings-v2-base-en"

# Custom local model
# CUSTOM_EMBEDDING_MODEL_PATH="/path/to/your/model"
# CUSTOM_EMBEDDING_MODEL_KWARGS='{"device": "cpu"}'

# LLM Configuration (Add keys for all providers you intend to use)
DEFAULT_LLM_PROVIDER="openai" # Or "deepseek", "qwen"
# OpenAI
OPENAI_API_KEY="your-openai-api-key" # Can be the same as embedding if applicable
OPENAI_MODEL_NAME="gpt-3.5-turbo"
# DeepSeek (Example - check actual env var names needed)
# DEEPSEEK_API_KEY="your-deepseek-api-key"
# DEEPSEEK_MODEL_NAME="deepseek-coder" # Or other models
# Qwen (Example - via Dashscope)
# DASHSCOPE_API_KEY="your-dashscope-api-key"
# QWEN_MODEL_NAME="qwen-turbo"

# API Configuration
API_HOST="0.0.0.0"
API_PORT=8000

# General Settings
PROJECT_NAME="Enterprise RAG System"
PROJECT_VERSION="0.1.0"
LOG_LEVEL="INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Milvus Configuration
MILVUS_TEXT_MAX_LENGTH=65535 # Max length for text field in Milvus schema
MILVUS_CONSISTENCY_LEVEL="Bounded" # Milvus consistency level (Strong, Bounded, Session, Eventually)
# Optional: Define Milvus index params as a JSON string if needed
# MILVUS_INDEX_PARAMS='{"metric_type":"L2","index_type":"AUTOINDEX","params":{}}'

# Embedding Model Configuration
EMBEDDING_DEVICE="cpu" # Device for local models ('cpu', 'cuda', 'mps')

# --- Provider Specific Settings ---
# OpenAI
OPENAI_EMBEDDING_MODEL_NAME="text-embedding-ada-002"
# HuggingFace (SentenceTransformers)
HUGGINGFACE_MODEL_NAME="sentence-transformers/paraphrase-multilingual-mpnet-base-v2" # Example multilingual model
# Qwen (Dashscope)
DASHSCOPE_API_KEY="your_dashscope_api_key"
QWEN_EMBEDDING_MODEL_NAME="text-embedding-v1"
# Ollama
OLLAMA_EMBEDDING_MODEL="nomic-embed-text" # Example model
# Jina
JINA_EMBEDDING_MODEL="jina-embeddings-v2-base-en" # Example model
# Custom Local Model (using HuggingFaceEmbeddings loader)
CUSTOM_EMBEDDING_MODEL_PATH="/path/to/your/local/model" # Absolute or relative path
# Optional: Custom model kwargs as JSON string e.g. '{"trust_remote_code": true}'
# CUSTOM_EMBEDDING_MODEL_KWARGS='{}'

# --- LLM Configuration ---
LLM_PROVIDER="openai" # Default LLM provider (e.g., openai, ollama, etc.)
# Add API keys/base URLs for different LLM providers as needed
OPENAI_LLM_API_KEY=${OPENAI_API_KEY} # Can reuse embedding key if applicable
OPENAI_LLM_MODEL_NAME="gpt-3.5-turbo"
OLLAMA_LLM_BASE_URL=${OLLAMA_BASE_URL}
OLLAMA_LLM_MODEL_NAME="llama3" # Example model
# Add other LLM provider configs...

# --- RAG Service Configuration ---
RETRIEVER_TOP_K=5
# Optional: Configure Cohere API Key if using rerank strategy
COHERE_API_KEY="your_cohere_api_key"

# --- API Server Configuration ---
CORS_ORIGINS="*" # Allow all for development

# --- Celery Configuration ---
CELERY_BROKER_URL="redis://localhost:6379/0"
CELERY_RESULT_BACKEND="redis://localhost:6379/1"
UPLOAD_TEMP_DIR="/tmp/rag_uploads" # Temporary storage for uploads before processing 