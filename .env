# Milvus Configuration
MILVUS_URI="grpc://localhost:19530"
MILVUS_TOKEN="your-milvus-api-key"
MILVUS_COLLECTION_NAME="rag_documents"

# Embedding Model Configuration
# Select ONE embedding provider
# Options: openai, huggingface, qwen, ollama, jina, custom
EMBEDDING_PROVIDER="openai"

# OpenAI Embeddings (Required if EMBEDDING_PROVIDER="openai")
OPENAI_API_KEY="your-openai-api-key"
OPENAI_EMBEDDING_MODEL_NAME="text-embedding-3-small"

# HuggingFace Embeddings
HUGGINGFACE_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"

# Qwen Embeddings (via Dashscope)
# Using DASHSCOPE_API_KEY (shared with LLM section)
QWEN_EMBEDDING_MODEL_NAME="text-embedding-v2"

# Ollama (local model)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_EMBEDDING_MODEL="llama2"

# Jina AI Embeddings
JINA_API_KEY="your-jina-api-key"
JINA_EMBEDDING_MODEL="jina-embeddings-v2-base-en"

# Custom local model
# CUSTOM_EMBEDDING_MODEL_PATH="/path/to/your/model"
# CUSTOM_EMBEDDING_MODEL_KWARGS='{"device": "cpu"}'

# LLM Configuration (Add keys for all providers you intend to use)
# Select the default LLM provider
# Options: openai, deepseek, qwen
DEFAULT_LLM_PROVIDER="openai"

# OpenAI LLM (Required if DEFAULT_LLM_PROVIDER="openai")
# Uses the same OPENAI_API_KEY as embeddings if provider is openai
OPENAI_MODEL_NAME="gpt-4o"

# DeepSeek (Example - check actual env var names needed)
# DEEPSEEK_API_KEY="your-deepseek-api-key"
# DEEPSEEK_MODEL_NAME="deepseek-coder"

# Qwen (Example - via Dashscope)
# DASHSCOPE_API_KEY="your-dashscope-api-key"
# QWEN_MODEL_NAME="qwen-turbo"

# API Configuration
API_HOST="0.0.0.0"
API_PORT=8000

# General Settings
PROJECT_NAME="Enterprise RAG System"
PROJECT_VERSION="0.1.0"
LOG_LEVEL="INFO"

# Milvus Configuration
MILVUS_TEXT_MAX_LENGTH=65535
MILVUS_CONSISTENCY_LEVEL="Bounded"
# Optional: Define Milvus index params as a JSON string if needed
# MILVUS_INDEX_PARAMS='{"metric_type":"L2","index_type":"AUTOINDEX","params":{}}'

# Embedding Model Configuration
EMBEDDING_DEVICE="cpu"

# --- Provider Specific Settings ---
# OpenAI
# OPENAI_EMBEDDING_MODEL_NAME="text-embedding-ada-002" # This is overridden by the main setting above

# HuggingFace (SentenceTransformers)
HUGGINGFACE_MODEL_NAME="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"

# Qwen (Dashscope)
DASHSCOPE_API_KEY="your_dashscope_api_key"
QWEN_EMBEDDING_MODEL_NAME="text-embedding-v1"

# Ollama
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"

# Jina
JINA_EMBEDDING_MODEL="jina-embeddings-v2-base-en"

# Custom Local Model (using HuggingFaceEmbeddings loader)
CUSTOM_EMBEDDING_MODEL_PATH="/path/to/your/local/model"

# Optional: Custom model kwargs as JSON string e.g. '{"trust_remote_code": true}'
# CUSTOM_EMBEDDING_MODEL_KWARGS='{}'

# --- LLM Configuration ---
# LLM_PROVIDER="openai" # This seems redundant, DEFAULT_LLM_PROVIDER is used
# Add API keys/base URLs for different LLM providers as needed
# OPENAI_LLM_API_KEY=${OPENAI_API_KEY} # Redundant, uses main key
OPENAI_LLM_MODEL_NAME="gpt-4o" # Ensure consistency

# --- RAG Service Configuration ---
RETRIEVER_TOP_K=5
# Optional: Configure Cohere API Key if using rerank strategy
COHERE_API_KEY="your_cohere_api_key"

# --- API Server Configuration ---
CORS_ORIGINS="*"
